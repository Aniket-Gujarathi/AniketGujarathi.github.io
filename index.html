<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aniket</title>

  <meta name="author" content="Aniket">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Aniket Sanjay Gujarathi</name>
              </p>
              <p>I am a graduate student at the University of Toronto pursuing an emphasis in robotics. Previously, I worked as an intern at Gatik.ai as a Software Engineer in the Perception Team.</a>
              I was also the Team Lead for the Radar Team at <a href="https://www.autodrive.utoronto.ca/">aUToronto</a> where I led a group of undergraduate and graduate students to develop algorithms for the perception stack of autonomous vehicles. 
              I also spent some time at Autonomous Space Robotics Lab (ASRL) under the guidance of <a href="http://asrl.utias.utoronto.ca/~tdb/">Prof. Tim Barfoot</a> where I worked on the project of deploying self-supervised lidar segmentation network on the Jackal Robot. I am interested in the general area of perception and deep-learning.
              </p>

              <p>
                Besides research, I enjoy singing, travelling and playing chess.

              </p>
<!--              <button onclick="research()">Research Interest</button>-->

              <p style="text-align:center">
                <a target="_blank" href="aniket.gujarathi@robotics.utias.utoronto.ca"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/Aniket-Gujarathi">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.co.in/citations?user=oz3PAHkAAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Aniket.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Aniket.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <h2>Background</h2> -->
        <p>
        <!-- with <a href="https://webdocs.cs.ualberta.ca/~dale/">Dale Schuurmans</a> and <a href="https://www.afaust.info/">Aleksandra Faust</a> in similar areas. -->
        <!-- I was fortunate to also work on consumer privacy rights and legislation with folks from <a href="https://www.law.georgetown.edu/privacy-technology-center">Georgetown's Center on Privacy and Technology.</a></p> -->
              </p>
              <p>
              </p>
        <h2>News</h2>

            <ul>
                    <li> <b> Dec 2022:</b> Completed the internship at Gatik.ai as a Software Engineer in the Perception Team.</li>
                    <li> <b> June 2022:</b> <a href="https://www.utoronto.ca/news/u-t-s-autoronto-team-wins-first-competition-autodrive-challenge-sequel">aUToronto</a> wins the first competition of the four-year AutoDrive Challenge 2 continuing the five year winning streak. </a></li>
                    <li> <b> May 2022:</b> Joining <a href="https://gatik.ai/">Gatik.ai</a> as a Software Engineering Intern with the Perception Team.</li>
                    <li> <b> Dec 2021:</b> Joining <a href="https://www.autodrive.utoronto.ca/">aUToronto</a> as the Radar Team Lead.</li>
                    <li> <b> Sept 2021:</b> Joining <a href="http://asrl.utias.utoronto.ca/">Autonomous Space Robotics Lab (ASRL)</a> as an MEng. student under the guidance of Prof. Tim Barfoot.</li>
                    <li> <b> Sept 2021:</b> Started MEng. at the University of Toronto Institute of Aerospace Studies with an emphasis in robotics.</li>
                    <li> <b> Oct 2021:</b> Paper published in IROS 2021: <a href="https://ieeexplore.ieee.org/abstract/document/9636619">RoRD: Rotation Robust Descriptors and Orthographic Views for Local Feature Matching</a> </li>
                  </ul>
            <!--<h2>Research 	&#129302;</h2>-->
        <h2>Projects</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                <!--
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/todo.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="todo_link">
                <papertitle>TODO_paper_title</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              TODO,
              <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>
              <br>
              <em>TODO conference venue</em>.
              <br>
              <p>TODO tldr</p>
            </td>
          </tr>
                -->
          <tr onmouseout="comp_attention_stop()" onmouseover="comp_attention_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/delivery.jpg" alt="kts" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2103.09229.pdf">
                <papertitle>Design and Development of Autonomous Delivery Robot</papertitle>
              </a>
              <br>
              <strong>Sharath Chandra Raparthy</strong>, Akshay Kulkarni, Unmesh Patil, Yogesh Phalak, Rajeshree Deotalu,
              Aman Jain, Navid Panchi, Ashwin Dhabale,
              and
              Shital S. Chiddarwar
              <br>
              <em>Capstone Project</em>.
              <br>
              [<a href="https://www.ivlabs.in/autonomous-driving-platform.html">Official Website</a>]
              <br>
              <p>
              We design and develop a low-cost autonomous delivery robot. The robot is equipped with multiple onboard sensors - Orbecc Astra Camera, YDLidar X4, IMU, and IR, for perception and state-estimation. The purpose of this project was to develop the autonomy stack for delivery robots.
</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/stair.jpg" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8675676">
                  <papertitle>Deep Learning Based Stair Detection and Statistical Image Filtering for Autonomous Stair Climbing</papertitle>
              </a> 
              <br>
              Unmesh Patil, <strong>Aniket Gujarathi</strong>, Akshay Kulkarni, Aman Jain, Lokeshkumar Malke, Radhika Tekade, Kartik Paigwar, and Pradyumn Chaturvedi
              <br>
              <em>IEEE International Conference on Robotic Computing (IRC)</em>
              <br>
              <a href="https://www.worldscientific.com/doi/abs/10.1142/S1793351X1940021X"> <papertitle>Deep Learning-Based Stair Segmentation and Behavioral Cloning for Autonomous Stair Climbing</papertitle>
              </a> 
              <br>
              Navid Panchi, Khush Agrawal, Unmesh Patil, <strong>Aniket Gujarathi</strong>, Aman Jain, Harsha Namdeo, and Shital S Chiddarwar
              <br>
              <em>International Journal of Semantic Computing</em>
              
                <br>
              [<a href="https://www.ivlabs.in/autonomous-multi-storey-surveillance-robot.html">Official Website</a>]
              <br>
              <p>In this work, we design a multi-storey surveillance robot that works on a novel distributed push-pull mechanism to climb stairs. We also add a camera to assist in detecting the stairs and estimating the relative pose to ensure accurate navigation. We further extend our idea to use stair segmentation and behavioral cloning for stair climbing. </p>
            </td>
          </tr>
  
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/meta-adr.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.07066">
                  <papertitle>Curriculum in Gradient-Based Meta-Reinforcement Learning</papertitle>
              </a>
              <br>
                Bhairav Mehta, Tristan Deleu*, <strong>Sharath Chandra*</strong> Christopher Pal, Liam Paull
                <br>
              <em>ICLR BeTR-RL workshop (2021)</em>
                <br>
              [
              <a href="https://arxiv.org/abs/2002.07956">Paper</a>]
                <br>
                <p>
                    In this work we study the under-studied parameter in meta learning, "Task Distributions". We show that Model Agnostic Meta-Learning (MAML) is sensitive to task distributions, and learning a curriculum of tasks instead of uniformly sampling helps the adaptation performance substantially.

                </p>
            </td>
          </tr>
<!--        <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="images/meta-adr.png" alt="hpp" style="border-style: none" width="200">-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--              <a href="https://arxiv.org/abs/2112.07066">-->
<!--                  <papertitle>Curriculum in Gradient-Based Meta-Reinforcement Learning</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--                Bhairav Mehta, Tristan Deleu*, <strong>Sharath Chandra*</strong> Christopher Pal, Liam Paull-->
<!--                <br>-->
<!--              <em>ICLR BeTR-RL workshop (2021)</em>-->
<!--                <br>-->
<!--              [-->
<!--              <a href="https://arxiv.org/abs/2002.07956">Paper</a>]-->
<!--                <br>-->
<!--                <p>-->
<!--                    In this work we study the under-studied parameter in meta learning, "Task Distributions". We show that Model Agnostic Meta-Learning (MAML) is sensitive to task distributions, and learning a curriculum of tasks instead of uniformly sampling helps the adaptation performance substantially.-->

<!--                </p>-->
<!--            </td>-->
<!--          </tr>-->
        <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/r:ss.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.07066">
                  <papertitle>CuNAS - CUriosity-driven Neural-Augmented Simulator</papertitle>
              </a>
              <br>
                <strong>Sharath Chandra Raparthy</strong>, Melissa Mozifian, Liam Paull and Florian Golemo
                <br>
              <em>RSS Sim2Real workshop (2021)</em>
                <br>
              [
              <a href="https://docs.google.com/presentation/d/1nVbt0iQKFTOgHEQLLHbn1Wy3bMs_mWpyzfc0aZsN30U/edit?usp=sharing">Slides</a> /
              <a href="https://www.youtube.com/watch?v=Tlf5RG3OPF8&list=PL4BpvvbNDc3SxmswMbOljlUcCQJQ6eFDL&index=6">Talk</a>]
              <br>
              <p>Transfer of policies from simulation to physical robots is an important open problem in deep reinforcement learning. Prior work has introduced the model-based Neural-Augmented Simulator (NAS) method, which uses task-independent data to create a model of the differences between simulated and real robot. In this work, we show that this method is sensitive to the sampling of motor actions and the control frequency. To overcome this problem, we propose a simple extension based on artificial curiosity. We demonstrate on a physical robot, that this leads to a better exploration of the state space and consequently better transfer performance when compared to the NAS baseline.</p>
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table>
  Template from <a href="https://jonbarron.info/">this website</a>.
</body>

</html>
